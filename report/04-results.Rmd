# Results

## Existing scenario evaluation

UTA, in partnership with VIA, ran a pilot program of microtransit service in south Salt Lake County from December 2019--November 2020. UTA reported several metrics from this program, which are presented in Table \@ref(tab:uta-metrics). Much of the data in that report, however, is not necessarily representative, due to the COVID-19 pandemic and its onset in late March 2020. We also considered that the data for December was not necessarily valuable: since the service was new, people who would otherwise have used it may not have been accustomed to or even known about it. We therefore decided to use the average of the data from January through March as our benchmark.

```{r uta-metrics}
tar_read(UTA_table) %>%
  kbl(booktabs = TRUE, digits = c(0,0,2,1), linesep = c(rep("", 12), "\\addlinespace"),
      caption = "Metrics Reported by UTA for the ODT Pilot Program in Salt Lake County") %>%
  row_spec(row = 13:14, bold = TRUE) %>%
  kable_styling()
```

We compared the results of our BEAM model of this program to the observed data. Our initial comparison showed that BEAM significantly over-predicted microtransit ridership and under-predicted wait times relative to the reported data, though after our calibration efforts, the results more closely matched the observed data. This comparison (with the calibrated BEAM scenario) is given in Table \@ref(tab:existing-comparison).

```{r existing-comparison}
tar_load(existing_comparison)

existing_comparison %>%
  kbl(booktabs = TRUE, digits = c(0,0,2,1),
      caption = "Comparison of Observed Data with 'Pilot' BEAM Scenario") %>%
  kable_styling()
```

At first glance, these results seem to be quite good, as the simulated scenario reports similar ridership and wait time metrics to the real-world data. However, it is important to consider that our model scenario uses a 20% population sample, and the observed data reflects the entire population. The model ODT fleet, on the other hand, was not scaled down to match the population sample size, and so represents the full fleet available in the real-world pilot program. The fact that the predicted ridership and wait time is so similar to the actual, measured values is nevertheless encouraging. This suggests that the predicted ridership and wait times in the other modeled scenarios are a somewhat realistic forecast, albeit a rough approximation.

There is also a significant discrepancy in the utilization measurements. Because of the way utilization is calculated (passengers per hour per vehicle), the vehicle operating hours can greatly affect this metric. In our model scenario, all 12 of the ODT vehicles are operational nearly all day, and it is likely that in off-peak hours the actual pilot program had fewer vehicles available.
<!-- If operating hours are taken to be only time that the ODT vehicles are in motion, then our modeled utilization becomes **TODO:** calculate this number. -->

## Candidate scenario comparison

We then ran each of our scenarios as described in section \@ref(scenario-configuration), and compared several metrics. These metrics include total ridership, utilization, and wait time, as in the previous comparison, but also includes median income of ODT users. These comparisons are given in Table \@ref(tab:scenario-compare).

```{r scenario-compare}
tar_read(scenario_comparison) %>% 
  kbl(booktabs = TRUE, digits = c(0,0,0,2,1,0),
      align = c('l', rep('r', 5)),
      caption = "Comparison Across BEAM Scenarios") %>% 
  kable_styling()
```

It is clear that in the scenarios with more microtransit vehicles available, ridership greatly increases. Interestingly, utilization does not vary much at all, which implies that at least in these specific scenarios there is a roughly linear relationship between number of vehicles and number of riders. This relationship can also be seen in the ratios of passengers to fleet size, as all of the vehicle operating hours are identical.

The median income of all persons is the same in each scenario, namely \$53,100. In nearly all of the model scenarios, the median income of ODT users is over \$10,000 less than this value. This comparison highlights the question of equity: ODT services seem to offer significantly more benefit to lower-income individuals. This suggests that ODT services would be most effective, at least from an equity standpoint, in lower-income areas.

Wait times for ODT services are very similar in each scenario. Not only are the average wait times nearly identical between scenarios (as shown in Table \@ref(tab:scenario-compare)), the distribution of wait times is essentially the same as well (Figure \@ref(fig:wait-time-compare)). It is important to note though that these wait times represent only _fulfilled_ ODT requests. In BEAM, when an agent makes an ODT request they may afterward re-plan and choose a different mode. This decision is largely based on the projected wait time for the ODT vehicle, so a request that returns a long wait time will often result in a change to mode choice. Table \@ref(tab:odt-fulfillment) compares the proportion of fulfilled requests in each scenario.

```{r wait-time-compare}
#| fig.cap="Comparison of ODT wait times in each scenario."

tar_read(wait_time_list) %>% 
 ggplot(aes(x = wait_time, y = Scenario, fill = Scenario)) +
  geom_violin() +
  stat_summary(fun = mean, geom = "crossbar") +
  theme_pander() +
  guides(fill = "none") +
  labs(x = "Time between ODT request and fulfillment",
       y = "Scenario")
```

```{r odt-fulfillment}
tar_read(rh_fulfillment_comparison) %>%
  kbl(booktabs = TRUE, digits = c(0,0,0,0,3),
      caption = "Comparison of Fulfilled and Unfulfilled ODT Requests") %>%
  add_header_above(c("", "ODT Requests" = 3, "")) %>% 
  kable_styling()
```

The proportion of ODT requests that were fulfilled does not vary much between the scenarios, though none of these values are particularly high. This shows that around 40%--45% of ODT requests return wait times considered too long, which results in a replanning of mode choice. The demand for ODT is clearly much higher than the supply, and so in our simulations the ODT fleets are fully saturated, regardless of which scenario is being run. This is further evidenced by the roughly linear relationship between fleet size and ridership (Table \@ref(tab:scenario-compare)). In fact, the proportion of unfulfilled ODT requests may be a good measure of fleet over-saturation, which could be useful in determining the optimal fleet size to match demand.
